{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxiKQe3pU6ih",
        "outputId": "0d5bce98-992e-4596-df20-90401f4602b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "\n",
        "## ----------------------- please set up data path echoDynamic.zip --------------------------------------------\n",
        "## --------------------------- paths where models are going to be saved ---------------------------------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PeTs1UpwU5rw"
      },
      "outputs": [],
      "source": [
        "import os,zipfile,keras\n",
        "zip_ref = zipfile.ZipFile('/content/drive/MyDrive/Major_Project/EchoNet-Dynamic.zip', 'r')\n",
        "zip_ref.extractall('/content/tmp')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5xUQ4BiwfwQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import cv2\n",
        "import keras\n",
        "from keras.layers import Conv2D,Input,LeakyReLU,BatchNormalization,Dropout,Concatenate,Dropout,GlobalAveragePooling2D,Dense,Flatten\n",
        "from keras.models import Model\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error\n",
        "import random \n",
        "PATH = {\n",
        "    'data_path' : \"/content/tmp/EchoNet-Dynamic/\", \n",
        "    'save_model': '/content/drive/MyDrive/Major Project/',\n",
        "    'figure_path' : '/content/drive/MyDrive/Major_Project/Figure/'\n",
        "}\n",
        "\n",
        "\n",
        "# ------------------------------------------------------- global DATA --------------------------\n",
        "# ------------------------------------ this will cause video data to erase --------------------\n",
        "# -------------------------------------- so think before execution ---------------------------\n",
        "\n",
        "TRAIN_SAMPLE_LOW = 0\n",
        "TRAIN_SAMPLE_HIGH = 9000 ## make it 6K \n",
        "TEST_SAMPLE_LOW = 7000 ## 6K\n",
        "TEST_SAMPLE_HIGH = 10000 ## 10K \n",
        "COMPRESSOR_EPOCHS = 5\n",
        "PREDICTOR_EPOCHS = 10\n",
        "\n",
        "fileList = pd.read_csv(PATH['data_path'] + 'FileList.csv')\n",
        "inputSize = TRAIN_SAMPLE_HIGH - TRAIN_SAMPLE_LOW + 1\n",
        "videoArrays = []\n",
        "EF = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttkCZl79VJN2"
      },
      "outputs": [],
      "source": [
        "## -------------------------------------------------------------- preprocessing -----------------------------------------------------------\n",
        "\n",
        "def VideoPreprocess(PATH,lower,upper):\n",
        "  ## EF and videoArrays generated\n",
        "  for i in range(lower,upper): \n",
        "    dfRow = fileList.iloc[i]\n",
        "    fileName = dfRow.FileName\n",
        "    path = PATH['data_path'] + \"/Videos/\" + fileName + '.avi'\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    if(frameCount < 100):\n",
        "       continue\n",
        "    buf = np.empty((112, 112,frameCount), np.dtype('uint8')) ### creating 50 frames size buffer\n",
        "    frameId = 0\n",
        "    for frameId in range(frameCount): \n",
        "      ret,frame = cap.read()\n",
        "      grayScale = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "      buf[:,:,frameId] = grayScale\n",
        "      del frame \n",
        "    videoArrays.append(buf)\n",
        "    EF.append(dfRow.EF)\n",
        "  return \n",
        "\n",
        "# --------------------------------------------- Layers ------------------------------------------\n",
        "\n",
        "\n",
        "def convS(input,filters,batch,stride,drop = 0.0): \n",
        "  ip = Input(shape = input.shape[1:])\n",
        "  output = Conv2D(filters = filters,kernel_size = (3,3),strides=stride)(ip)\n",
        "  if batch: \n",
        "    output = BatchNormalization()(output)\n",
        "  output = LeakyReLU(alpha=.2)(output)\n",
        "  if drop: \n",
        "    output = Dropout(drop)(output)\n",
        "  model = Model(ip,output)\n",
        "  return model(input)\n",
        "def concatenatedLayers(input1,input2,filters,batch,drop):\n",
        "  ip1 = Input(shape = input1.shape[1:])\n",
        "  ip2 = Input(shape = input2.shape[1:])\n",
        "  concat = Concatenate()([ip1,ip1])\n",
        "  output = Conv2D(filters = filters,kernel_size = (3,3),strides=(1,1),padding='same')(concat)\n",
        "  if batch: \n",
        "    output = BatchNormalization()(output)\n",
        "  output = LeakyReLU(alpha=.2)(output)\n",
        "  if drop:\n",
        "    output = Dropout(drop)(output)\n",
        "  model = Model([ip1,ip2],output)\n",
        "  return model([input1,input2])\n",
        "def convLayer(input,filters,batch,drop): \n",
        "  ip = Input(shape = input.shape[1:])\n",
        "  output = Conv2D(filters = filters,kernel_size = (3,3),strides=(1,1),padding='same')(ip)\n",
        "  if batch: \n",
        "    output = BatchNormalization()(output)\n",
        "  output = LeakyReLU(alpha=.2)(output)\n",
        "  if drop:\n",
        "    output = Dropout(drop)(output)\n",
        "  model = Model(ip,output)\n",
        "  return model(input)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------- generator MODEL ---------------------------------------------------------------------\n",
        "\n",
        "def generation(): \n",
        "  input = Input(shape=(112,112,50)) \n",
        "  gen = convLayer(input = input,filters = 64,batch = True,drop = 0.0)\n",
        "  gen = convLayer(input = gen,filters = 128,batch = True,drop = 0.2)\n",
        "  gen = convLayer(input = gen,filters = 256,batch = True,drop = .4)\n",
        "  gen = concatenatedLayers(input1 = gen,input2 = input,filters = 64,batch = False, drop = 0.2) \n",
        "  gen = convLayer(input = gen,filters = 32,batch = False,drop = .1)\n",
        "  gen = convLayer(input = gen,filters = 16,batch = False,drop = 0.0)\n",
        "  gen = Conv2D(filters = 1,kernel_size = (3,3),strides=(1,1),padding='same',activation = 'tanh')(gen)\n",
        "  model = Model(input,gen) \n",
        "  return model\n",
        "\n",
        "# ----------------------------------------------------------- regenerator model ----------------------------------------------------------------------------\n",
        "\n",
        "def regeneration():\n",
        "  inputReal = Input(shape = (112,112,2))\n",
        "  regen = convLayer(input = inputReal,filters = 16,batch = True,drop = 0.0)\n",
        "  regen = convLayer(input = regen,filters = 32,batch = True,drop = 0.0)\n",
        "  regen = convLayer(input = regen,filters = 64,batch = True,drop = 0.1)\n",
        "  regen = concatenatedLayers(input1 = regen,input2 = inputReal,filters = 128,batch = True, drop = 0.2)\n",
        "  regen = convLayer(input = regen,filters = 128,batch = False,drop = 0.1)\n",
        "  regen = convLayer(input = regen,filters = 64,batch = False,drop = 0.0)\n",
        "  regen = Conv2D(filters = 50,kernel_size = (3,3),strides = (1,1), padding = \"same\",activation = 'tanh')(regen)\n",
        "  model = Model(inputReal,regen)\n",
        "  return model\n",
        "\n",
        "# ----------------------------------------------------------- compressor MODEL \n",
        "\n",
        "def compressor(PATH,lr = 0.001):\n",
        "  image = Input(shape = (112,112,1))\n",
        "  volume = Input(shape = (112,112,50))\n",
        "  generate = generation() \n",
        "  regenerate = regeneration()\n",
        "  generatedImage = generate(volume)\n",
        "  images = Concatenate()([image,generatedImage])\n",
        "  finalVolume = regenerate(images)\n",
        "  regen = Model([image,volume],finalVolume)\n",
        "  regen.compile(optimizer = Adam(learning_rate = lr),loss = 'mae')\n",
        "  plot_model(generate, to_file=PATH['figure_path'] + 'generator.png', show_shapes=True, show_layer_names=False)\n",
        "  plot_model(regenerate, to_file=PATH['figure_path'] + 'regenerator.png', show_shapes=True, show_layer_names=False)\n",
        "  plot_model(regen, to_file=PATH['figure_path'] + 'pipeline.png', show_shapes=True, show_layer_names=False)\n",
        "  return regen,generate\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------- compressor generator ------------------------------------------------------\n",
        "class compressorDataGenerator(keras.utils.Sequence):\n",
        "  'Generates data for Keras'\n",
        "  def __init__(self, PATH):\n",
        "    'Initialization'\n",
        "    self.batch_size = 1\n",
        "    self.len = len(videoArrays) ## global fileList \n",
        "    self.on_epoch_end()  \n",
        "    self.index = 0\n",
        "\n",
        "  def __len__(self):\n",
        "    'Denotes the number of batches per epoch'\n",
        "    return self.len \n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    'Generate one batch of data'\n",
        "    X, y = self.__data_generation(self.index)\n",
        "    return X, y\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    'Updates indexes after each epoch'\n",
        "    self.index = random.randrange(0,self.len-1) ## taking random number in range \n",
        "\n",
        "  def __data_generation(self, index):\n",
        "    'Generates data containing batch_size samples'\n",
        "\n",
        "    ## it's in 112x112xFRAMES shape\n",
        "    video = videoArrays[index]\n",
        "    video = (video - 127.5)/127.5 ## tranforming Video Arrays \n",
        "    datasetX = np.empty((video.shape[0]//50,112,112,50))\n",
        "    datasetY = np.empty((video.shape[0]//50,112,112,1))\n",
        "    datasetZ = np.empty((video.shape[0]//50,112,112,50))\n",
        "    i = 0\n",
        "    while(i + 50 <= video.shape[0]): \n",
        "      x = video[:,:,i:i+50]\n",
        "      image = x[:,:,1:2]\n",
        "      datasetX[i//50] = x\n",
        "      datasetZ[i//50] = x \n",
        "      datasetY[i//50] = image\n",
        "      i+=50\n",
        "      # del image,x \n",
        "    return [datasetY,datasetX],datasetZ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dorkeq2Zidbs"
      },
      "outputs": [],
      "source": [
        "## -------------------------------------------- video.npy generation ------------------------------------------\n",
        "\n",
        "VideoPreprocess(PATH,TRAIN_SAMPLE_LOW,TRAIN_SAMPLE_HIGH) \n",
        "\n",
        "## 23 GB for 9000 dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tlLZQ9fnZEJ",
        "outputId": "4deab314-e6d3-4893-e3b4-cee142018cc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-164d4554d703>:6: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  final.fit_generator(generator,epochs = COMPRESSOR_EPOCHS,workers = 4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "8705/8705 [==============================] - 504s 56ms/step - loss: 0.0464\n",
            "Epoch 2/5\n",
            "8705/8705 [==============================] - 494s 57ms/step - loss: 0.0452\n",
            "Epoch 3/5\n",
            "8705/8705 [==============================] - 493s 57ms/step - loss: 0.0324\n",
            "Epoch 4/5\n",
            "8705/8705 [==============================] - 493s 57ms/step - loss: 0.0394\n",
            "Epoch 5/5\n",
            "8705/8705 [==============================] - 494s 57ms/step - loss: 0.0283\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "# ------------------------- training compressor ------------------------------\n",
        "\n",
        "\n",
        "final,gen = compressor(PATH,lr = .0005)\n",
        "generator = compressorDataGenerator(PATH)\n",
        "final.fit_generator(generator,epochs = COMPRESSOR_EPOCHS,workers = 4)\n",
        "final.save(PATH['save_model'] + 'wholeTestingFinal.h5')\n",
        "gen.save(PATH['save_model'] + 'wholeTestingGen.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del videoArrays,EF\n",
        "videoArrays = []\n",
        "EF = []\n",
        "VideoPreprocess(PATH,9000,10000) "
      ],
      "metadata": {
        "id": "fmhv9k2wpI1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = compressorDataGenerator(PATH)\n",
        "final.fit_generator(generator,epochs = COMPRESSOR_EPOCHS,workers = 4)\n",
        "final.save(PATH['save_model'] + 'wholeTestingFinalWhole.h5')\n",
        "gen.save(PATH['save_model'] + 'wholeTestingGenWhole.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHHoZK6TpBW2",
        "outputId": "d950c20b-3d04-4973-e16d-7a66579bf208"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-08515563f233>:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  final.fit_generator(generator,epochs = COMPRESSOR_EPOCHS,workers = 4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "961/961 [==============================] - 55s 57ms/step - loss: 0.0467\n",
            "Epoch 2/5\n",
            "961/961 [==============================] - 54s 57ms/step - loss: 0.0415\n",
            "Epoch 3/5\n",
            "961/961 [==============================] - 55s 57ms/step - loss: 0.0437\n",
            "Epoch 4/5\n",
            "961/961 [==============================] - 54s 57ms/step - loss: 0.0501\n",
            "Epoch 5/5\n",
            "961/961 [==============================] - 55s 57ms/step - loss: 0.0331\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del videoArrays,EF\n",
        "videoArrays = []\n",
        "EF = []\n",
        "VideoPreprocess(PATH,0,1000) \n",
        "generator = compressorDataGenerator(PATH)\n",
        "final.fit_generator(generator,epochs = 2,workers = 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEoFExh-zr71",
        "outputId": "92fa7c94-fb67-4f4c-b326-884f08026dc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "  1/969 [..............................] - ETA: 1:59 - loss: 0.0898"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-0b495427fbe8>:6: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  final.fit_generator(generator,epochs = 2,workers = 4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "969/969 [==============================] - 55s 57ms/step - loss: 0.0486\n",
            "Epoch 2/2\n",
            "969/969 [==============================] - 55s 57ms/step - loss: 0.0485\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f56fc7633a0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del videoArrays,EF\n",
        "videoArrays = []\n",
        "EF = []\n",
        "VideoPreprocess(PATH,5000,6000) \n",
        "generator = compressorDataGenerator(PATH)\n",
        "final.fit_generator(generator,epochs = 1,workers = 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoGyocjT1c26",
        "outputId": "aff2f5c5-8478-47af-e25b-ffc27318a265"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  1/961 [..............................] - ETA: 1:51 - loss: 0.1010"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-345609a833aa>:6: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  final.fit_generator(generator,epochs = 1,workers = 4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "961/961 [==============================] - 55s 58ms/step - loss: 0.0389\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f55b01e6890>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final.save(PATH['save_model'] + 'wholeTestingFinalGeneralized.h5')\n",
        "gen.save(PATH['save_model'] + 'wholeTestingGeneralized.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBSJ0O-M1-92",
        "outputId": "40534997-820b-4a63-8413-29fb1a71e43f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r-dSRE3k2bW6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}